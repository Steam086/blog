
在分析vllm的分布式代码时，总结出流水线并行的核心逻辑：

1. 判断处在流水线中的位置 
2. 根据是否是第一个或者最后一个位置进行不同处理
3. 如果不是最后一个位置，返回 `[None]`，如果是，返回`output`
- `get_pp_group().is_last_rank` 与`get_pp_group().is_first_rank:`判断是否处在流水线的第一个位置或者最后一个位置，true->进行特殊处理，false->从流水线组中的前一个设备获取输入（`intermediate_tensors`）进行前向传播后传递给下一个设备。
- 从上一个设备获取输入的方法`recv_tensor_dict()`，传递给下一个设备的方法`send_tensor_dict()`
- 上述send和recv所传递的参数是一个`tensor_dict`是一个`Dict[str, torch.Tensor]`


```Python
get_pp_group().send_tensor_dict(output.tensors,all_gather_group=get_tp_group())
```

